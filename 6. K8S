K8S:

k8's is an open-source container orchestration platform.
useing which automates many of the manual processes like deploying, managing, and scaling containerized applications.
Kubernetes was developed by GOOGLE using GO Language.
Google donated K8's to CNCF in 2014.
1st version was released in 2015.

ARCHITECTURE:

DOCKER : CNCA
K8S: CNPCA

C : CLUSTER
N : NODE
P : POD
C : CONTAINER
A : APPLICATION

NOTE: k8s doesn't communicate with containers.
it communicate with pods.



COMPONENTS:
MASTER:

1. API SERVER: communicate with user which takes command execute it & gives op.
2. ETCD: database of cluster which stores complete information of a cluster.
3. SCHEDULER: schedules pods on worker node which is depends on h/w of node.


3. SCHEDULER: select the worker node to shedule pods depends on hw of node
4. CONTROLLER: control the k8s objects (n/w, service, volume)

WORKER:

1. KUBELET : its an agent which informs all activites to master node.
2. KUBEPROXY: it deals with nlw i.e, ip, networks, ports.
3. POD : group of conatiners inside pod we have applications.


CLUSTER:
1. SELF MANAGED CLUSTER: WE NEED TO CREATE & MANAGE THEM

minikube = single node cluster
kubeadm = multi node cluster (manual)
kops = multi node cluster (automation)

2. CLOUD BASED CLUSTER: WE NEED TO CREATE AND CLOUD PROVIDERS WILL MANAGE THEM

AWS = EKS = ELASTIC KUBERNETES SERVICE
AZURE = AKS = AZURE KUBERENETS SERVICE
GOOGLE = GKS = GOOGLE KUBERENETS SERVICE



MINIKUBE:
It is a tool used to setup single node cluster on K8's. 
It contains API Servers, ETDC database and container runtime
It is used for development, testing, and experimentation purposes on local. 
Here Master and worker runs on same machine
It is a platform Independent.
Installing Minikube is simple compared to other tools.

NOTE: But we dont implement this in real-time Prod

REQUIREMENTS:

2 CPUs or more  ubuntu
2GB of free memory
20GB of free disk space
Internet connection
Container or virtual machine manager, such as: Docker.

Kubectl is the command line tool for k8s
if we want to execute commands we need to use kubectl.

SETUP:
sudo apt update -y
sudo apt upgrade -y
sudo apt install curl wget apt-transport-https -y
sudo curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo mv minikube-linux-amd64 /usr/local/bin/minikube
sudo chmod +x /usr/local/bin/minikube
sudo minikube version
sudo curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo curl -LO "https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"
sudo echo "$(cat kubectl.sha256) kubectl" | sha256sum --check
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
sudo minikube start --driver=docker --force

POD:
It is a smallest unit of deployment in K8's.
It is a group of containers.
Pods are ephemeral (short living objects)
'Mostly we can use single container inside a pod' but if we required, we can create multiple containers inside a same pod.
when we create a pod, 'containers inside pods can share the same network namespace, and can share the same storage volumes' .
While creating pod, 'we must specify the image', along with any necessary configuration and resource limits.
'K8's cannot communicate with containers', 'they can communicate with only pods'.
 We can create this pod in two ways, 
1. Imperative(command) 
2. Declarative (Manifest file)


IMPERATIVE:

kubectl run pod1 --image vinodvanama/paytmmovies:latest
kubectl get pod
kubectl get pod -o wide
kubectl describe pod pod1
kubectl delete pod pod2

DECRALATIVE:

vim pod.yml

apiVersion: v1
kind: Pod
metadata:
  name: pod1
spec:
  containers:
    - image: vinodvanama/paytmtrain:latest
      name: cont1

kubectl create -f pod.yml
kubectl apply -f pod.yml

DRAWBACK:
if we delete the pod we cant retrive the pod.
all the load will be handled by single pod.

HISTORY:
 1  vim minikube.sh
    2  sh minikube.sh
    3  minikube status
    4  kubectl run pod1 --image vinodvanama/paytmmovies:latest
    5  kubectl get pod
    6  kubectl run pod2 --image vinodvanama/paytmtrain:latest
    7  kubectl get pod
    8  kubectl grt pod -o wide
    9  kubectl get pod -o wide
   10  kubectl describe pod pod1
   11  kubectl delete pod pod2
   12  kubectl get pod
   13  kubectl delete pod pod1
   14  vim pod.yml
   15  kubectl create -f pod.yml
   16  kubectl get pod
   17  kubectl describe pod pod1
   18  cat pod.yml
   19  history
===============================================
REPLICASET:
it will create multiple copies of same pod.
if we delete one pod automatically it will create new pod.


LABELS: is used to craete the particular pods as a single unit.
SELECTOR: Used to select pods with same labels.


vim replicaset.yml

apiVersion: apps/v1
kind: ReplicaSet
metadata:
  labels:
    app: swiggy
  name: swiggy-rs
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
      - name: cont1
        image: nginx


To list rs		:kubectl get rs/replicaset
To show addtional info	:kubectl get rs -o wide
To show complete info	:kubectl describe rs name-of-rs
To delete the rs	:kubectl delete rs name-of-rs
to get lables of pods 	: kubectl get pods -l app=swiggy
TO scale rs		: kubectl scale rs/swiggy-rs --replicas=10 (LIFO)

DRAWBACKS:
1. we cannot rollin and rollout and  we cannot update the application in rs.

DEPLOYMENT:
deploy -- > rs -- > pods
we can update the application.
its high level k8s objects.

vim deploy.yml

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: swiggy
  name: swiggy-rs
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
      - name: cont1
        image: nginx


To list deployment	:kubectl get deploy
To show addtional info	:kubectl get deploy -o wide
To show complete info	:kubectl describe deploy name-of-deployment
To delete the deploy	:kubectl delete deploy name-of-deploy
to get lables of pods 	:kubectl get pods -l app=swiggy
TO scale deploy		:kubectl scale deploy/name-of-deploy --replicas=10 (LIFO)
To edit deploy		:kubectl edit deploy/name-of-deploy
to show all pod labels	:kubectl get pods --show-labels
To delete all pods	:kubectl delete pod --all



HISTORY:
 1  vim minikube.sh
    2  sh minikube.sh
    3  vim rs.yml
    4  kubectl get pods
    5  kubectl create -f rs.yml
    6  kubectl get pods
    7  kubectl get pods --show labels
    8  kubectl get pods -l swiggy
    9  kubectl get pods -l=swiggy
   10  kubectl get pods
   11  kubectl describe pod swiggy-rs-h4f6x
   12  kubectl get pods -l app=swiggy
   13  kubectl delete pod swiggy-rs-h4f6x
   14  kubectl get pods
   15  kubectl delete pod swiggy-rs-9ks7n
   16  kubectl get pods
   17  kubectl get replicaset
   18  kubectl get rs
   19  kubectl get rs -o wide
   20  kubectl describe rs swiggy-rs
   21  kubectl delete rs swiggy-rs
   22  kubectl get po
   23  cat rs.yml
   24  kubectl api-resource
   25  kubectl api-resources
   26  cat rs.yml
   27  kubectl create -f rs.yml
   28  kubectl get rs
   29  kubectl get rs -o wide
   30  kubectl describe rs swiggy-rs
   31  kubectl delete rs swiggy-rs
   32  kubectl get rs
   33  kubectl get po
   34  kubectl create -f rs.yml
   35  kubectl get rs
   36  kubectl get po
   37  kubectl scale rs/swiggy-rs --scale=10
   38  kubectl scale rs/swiggy-rs --replicas=10
   39  kubectl get po
   40  kubectl scale rs/swiggy-rs --replicas=5
   41  kubectl get po
   42  kubectl delete rs swiggy-rs
   43  vim rs.yml
   44  kubectl apply -f rs.yml
   45  kubectl get deploy
   46  kubectl get rs
   47  kubectl get pods
   48  kubectl describe deploy swiggy-rs
   49  kubectl get pods
   50  kubectl describe pod swiggy-rs-6d6f49d7cd-rqf84
   51  kubectl describe pod swiggy-rs-6d6f49d7cd-ts6jq
   52  kubectl edit deploy/swiggy-rs
   53  kubectl describe deploy swiggy-rs
   54  kubectl get po
   55  kubectl delete pod swiggy-rs-64956f47f-9q6mn
   56  kubectl describe pod swiggy-rs-64956f47f-c46ss
   57  kubectl describe pod swiggy-rs-64956f47f-g9cf8
   58  kubectl edit deploy/swiggy-rs
   59  kubectl get rs
   60  kubectl describe deploy
   61  kubectl get po
   62  kubectl scale deploy/swiggy-rs --replicas=20
   63  kubectl get po
   64  kubectl scale deploy/swiggy-rs --replicas=3
   65  kubectl get po
   66  kubectl run pod1 --image vinodvanama/paytmmovies:latest
   67  kubectl run pod2 --image vinodvanama/paytmmovies:latest
   68  kubectl run pod3 --image vinodvanama/paytmmovies:latest
   69  kubectl get po
   70  kubectl get po -l app=swiggy
   71  kubectl get po --help
   72  kubectl get po
   73  kubectl get po -o wide
   74  kubectl get po -o wide --show --help
   75  kubectl get po --show --help
   76  kubectl get po --show -h
   77  kubectl get po --labels
   78  kubectl get po -l --help
   79  kubectl get rs -o wide
   80  kubectl get pods --show-labels
   81  kubectl delete pod -A
   82  kubectl delete pod -A default

   83  kubectl delete pod --all default
   84  kubectl delete pod --all
   85  history
root@ip-172-31-17-73:~#
SCALING: 

SCALE-IN: Increasing the count of pods
kubectl scale rs/swiggy-rs --replicas=10

SCALE-OUT: Decreasing the count of pods
kubectl scale rs/swiggy-rs --replicas=5

SCALING FOLLOWS LIFO PATTERN:
LIFO: LAST IN FIRST OUT
the pod which is created will be deleted first automatically when we scale out.


=======================================================
KOPS:
INFRASTRUCTURE: Resources used to run our application on cloud.
EX: Ec2, VPC, ALB, -------------
Highly availablility : More than one server

Minikube -- > single node cluster
All the pods on single node 
kOps, also known as Kubernetes operations.
it is an open-source tool that helps you create, destroy, upgrade, and maintain a highly available, production-grade Kubernetes cluster. 
Depending on the requirement, kOps can also provide cloud infrastructure.
kOps is mostly used in deploying AWS and GCE Kubernetes clusters. 
But officially, the tool only supports AWS. Support for other cloud providers (such as DigitalOcean, GCP, and OpenStack) are in the beta stage.


ADVANTAGES:
•	Automates the provisioning of AWS and GCE Kubernetes clusters
•	Deploys highly available Kubernetes masters
•	Supports rolling cluster updates
•	Autocompletion of commands in the command line
•	Generates Terraform and CloudFormation configurations
•	Manages cluster add-ons.
•	Supports state-sync model for dry-runs and automatic idempotency
•	Creates instance groups to support heterogeneous clusters

ALTERNATIVES:
Amazon EKS , MINIKUBE, KUBEADM, RANCHER, TERRAFORM.
2/2 check:
===========
1.system check.
2.instance check --means Hardware properties like cpu ram comes under instance check.

PREREQUSITES:
iam: to give permission to create infra
bucket: used to store cluster info
versioning: to retrive the deleted objects on bucket

vim .bashrc
export PATH=$PATH:/usr/local/bin/  -- > save and exit
source .bashrc

aws configure

STEP-1: GIVING PERMISSIONS
IAM -- > USER -- > CREATE USER -- > NAME: KOPS -- > Attach Polocies Directly -- > AdministratorAccess -- > NEXT -- > CREATE USER
USER -- > SECURTITY CREDENTIALS -- > CREATE ACCESS KEYS -- > CLI -- > CHECKBOX -- >  CREATE ACCESS KEYS -- > DOWNLOAD 

SETP-2: INSTALL KUBECTL AND KOPS

curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
chmod +x kops-linux-amd64 kubectl
mv kubectl /usr/local/bin/kubectl
mv kops-linux-amd64 /usr/local/bin/kops


SETP-3: CREATEING BUCKET 
aws s3api create-bucket --bucket devopsbyraham007.k8s.local --region us-east-1
aws s3api put-bucket-versioning --bucket cloudanddevopsbyraham007.k8s.local --region us-east-1 --versioning-configuration Status=Enabled
export KOPS_STATE_STORE=s3://cloudanddevopsbyraham007.k8s.local

SETP-4: CREATING THE CLUSTER
kops create cluster --name rahams.k8s.local --zones us-east-1a --master-count=1 --master-size t2.medium --node-count=2 --node-size t2.micro
kops update cluster --name rahams.k8s.local --yes --admin


Suggestions:
 * list clusters with: kops get cluster
 * edit this cluster with: kops edit cluster rahams.k8s.local
 * edit your node instance group: kops edit ig --name=rahams.k8s.local nodes-us-east-1a
 * edit your master instance group: kops edit ig --name=rahams.k8s.local master-us-east-1a


ADMIN ACTIVITIES:
To scale the worker nodes:
kops edit ig --name=rahams.k8s.local nodes-us-east-1a
kops update cluster --name rahams.k8s.local --yes --admin 
kops rolling-update cluster --yes

kubectl describe node node_id
kops delete cluster --name rahams.k8s.local --yes


HISTORY:
1  vim .bashrc
    2  source .bashrc
    3  aws configure
    4  curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubec                                                                                                                   tl"
    5  wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
    6  ll
    7  chmod +x kops-linux-amd64 kubectl
    8  ll
    9  mv kubectl /usr/local/bin/kubectl
   10  mv kops-linux-amd64 /usr/local/bin/kops
   11  kops --version
   12  kubectl --version
   13  kubectl version
   14  kops version
   15  wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
   16  aws s3api create-bucket --bucket rahamssshaik09.k8s.local --region us-east-1
   17  aws s3api create-bucket --bucket vinodvanamaa007.k8s.local --region us-east-1
   18  aws s3api put-bucket-versioning --bucket vinodvanamaa007.k8s.local --region us-east-1 --versioning-configura                                                                                                                   tion Status=Enabled
   19  export KOPS_STATE_STORE=s3://vinodvanamaa007.k8s.local
   20  kops create cluster --name rahams.k8s.local --zones us-east-1a --master-count=1 --master-size t2.medium --no                                                                                                                   de-count=2 --node-size t2.micro
   21   kops update cluster --name rahams.k8s.local --yes --admin
   22   kops validate cluster --wait 10m
   23  kops get cluster
   24  kubectl get no
   25  kops edit ig --name=rahams.k8s.local nodes-us-east-1a
   26  kops update cluster --name rahams.k8s.local --yes
   27   kops rolling-update cluster
   28  kubectl get no
   29  kops edit ig --name=rahams.k8s.local nodes-us-east-1a
   30  kops rolling-update cluster
   31  kops update cluster --name rahams.k8s.local --yes
   32  kops rolling-update cluster
   33  kops edit ig --name=rahams.k8s.local master-us-east-1a
   34  kops update cluster --name rahams.k8s.local --yes
   35  kops edit ig --name=rahams.k8s.local master-us-east-1a
   36  kops update cluster --name rahams.k8s.local --yes
   37  kops rolling-update cluster
   38  kubectl get no
   39  kops get cluster
   40  kops delete cluster --name rahams.k8s.local --yes
   41  kops get cluster
   42  history

or

INFRASTRUCUTRE: Resource used to run our application on cloud.
EX: servers, Vpc, LB, Asg
Highly availablility : More than one server

KOPS:

Minikube -- > single node cluster
All the pods on single node 
kOps, also known as Kubernetes operations, is an open-source tool that helps you create, destroy, upgrade, and maintain a highly available, production-grade Kubernetes cluster. 
Depending on the requirement, kOps can also provide cloud infrastructure.
kOps is mostly used in deploying AWS and GCE Kubernetes clusters. 
But officially, the tool only supports AWS. 
Support for other cloud providers (such as DigitalOcean, GCP, and OpenStack) are in the beta stage.

ADVANTAGES:
•	Automates the provisioning of AWS and GCE Kubernetes clusters
•	Deploys highly available Kubernetes masters
•	Supports rolling cluster updates
•	Autocompletion of commands in the command line
•	Generates Terraform and CloudFormation configurations
•	Manages cluster add-ons.
•	Supports state-sync model for dry-runs and automatic idempotency
•	Creates instance groups to support heterogeneous clusters
ALTERNATIVES:
Amazon EKS , MINIKUBE, KUBEADM, RANCHER, TERRAFORM, HELM.


keys -- > iam -- > user -- > craete users -- > name: kops -- > attach polocies directly -- > AdministratorAccess -- > next -- > create 
select user -- > security credentials -- > Access keys -- > create Access keys 
-- > cli -- > confirm -- > crearte Access keys -- > download file


PREREQUSITES:
iam: to give permission to create infra
bucket: used to store cluster info
versioning: to retrive the deleted objects on bucket

SETUP:

#vim .bashrc
#export PATH=$PATH:/usr/local/bin/
#source .bashrc


#! /bin/bash
aws configure
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
chmod +x kops-linux-amd64 kubectl
mv kubectl /usr/local/bin/kubectl
mv kops-linux-amd64 /usr/local/bin/kops

aws s3api create-bucket --bucket rahamssshaik09.k8s.local --region us-east-1
aws s3api put-bucket-versioning --bucket rahamssshaik09.k8s.local --region us-east-1 --versioning-configuration Status=Enabled
export KOPS_STATE_STORE=s3://rahamssshaik09.k8s.local

kops create cluster --name rahams.k8s.local --zones us-east-1a --master-count=1 --master-size t2.medium --node-count=2 --node-size t2.micro
kops update cluster --name rahams.k8s.local --yes --admin

kubectl get no
kops get cluster


Suggestions:
 * list clusters with: kops get cluster
 * edit this cluster with: kops edit cluster rahams.k8s.local
 * edit your node instance group: kops edit ig --name=rahams.k8s.local nodes-us-east-1a
 * edit your master instance group: kops edit ig --name=rahams.k8s.local master-us-east-1a

Finally configure your cluster with: kops update cluster --name rahams.k8s.local --yes --admin


CLUSTER ADMIN ACTIVITIES:

SCALING THE NODES:
kops edit ig --name=rahams.k8s.local nodes-us-east-1a
kops edit ig --name=rahams.k8s.local nodes-us-east-1a (MIN AND MX REPLACE WITH 4)
kops update cluster --name rahams.k8s.local --yes --admin
kops rolling-update cluster

To delete cluster: kops delete cluster --name rahams.k8s.local --yes
Note: bucket will not delete


===============================================

DAY 2 FOR KOPS:
CRIPT:
RUN BELOW COMMANDS MANUALLY
#vim .bashrc
#export PATH=$PATH:/usr/local/bin/
#source .bashrc


#! /bin/bash
aws configure
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
chmod +x kops-linux-amd64 kubectl
mv kubectl /usr/local/bin/kubectl
mv kops-linux-amd64 /usr/local/bin/kops

aws s3api create-bucket --bucket fayaz1993recharge --region ca-central-1
aws s3api put-bucket-versioning --bucket fayaz1993recharge --region ca-central-1 --versioning-configuration Status=Enabled
export KOPS_STATE_STORE=s3://fayaz1993recharge
kops create cluster --name kopsssy.k8s.local --zones ca-central-1a --master-count=1 --master-size t2.medium --node-count=2 --node-size t2.micro
kops update cluster --name kopsy.k8s.local --yes --admin


RUN COMMAND AFTER SCRIPT
export KOPS_STATE_STORE=s3://fayaz1993recharge
kops validate cluster --wait 10m

==================================================================
NAMESPACES:

NAMESPACE: It is used to divide the cluster to multiple teams on real time.
it is used to isolate the env.

CLUSTER: HOUSE
NAMESPACES: ROOM

Each namespace is isolated.
if your are room-1 are you able to see room-2.
we cant access the objects from one namespace to another namespace.


TYPES:

default           : Is the default namespace, all objects will create here only
kube-node-lease   : it will store object which is taken from one namespace to another.
kube-public	  : all the public objects will store here.      
kube-system 	  : default k8s will create some objects, those are storing on this ns.

kubectl get pod -n kube-system	: to list all pods in kube-system namespace
kubectl get pod -n default	: to list all pods in default namespace
kubectl get pod -n kube-public	: to list all pods in kube-public namespace
kubectl get po -A		: to list all pods in all namespaces

kubectl create ns dev	: to create namespace
kubectl config set-context --current --namespace=dev : to switch to the namespace
kubectl config view --minify | grep namespace : to see current namespace
kubectl delete ns dev	: to delete namespace
kubectl delete pod --all: to delete all pods


NOTE: By deleting  the ns all objects also gets deleted.
in real time we use rbac concept to restrict the access from one namespace to another.
so users cant access/delete ns, because of the restriction we provide.
we create roles and rolebind for the users.


KUBECOLOR:

wget https://github.com/hidetatz/kubecolor/releases/download/v0.0.25/kubecolor_0.0.25_Linux_x86_64.tar.gz
tar -zxvf kubecolor_0.0.25_Linux_x86_64.tar.gz
./kubecolor
chmod +x kubecolor
mv kubecolor /usr/local/bin/
kubecolor get po

==============================================================================
DAY 3 FOR KOPS:

SERVICE: It is used to expose the application in k8s.

TYPES:
1. CLUSTERIP: It will expose the application inside the cluster only.
it will not expose the application to outside of world.
EX:1.If we hava DataBase server, for the server we cannot give access to all people.We can give only for Organization People i.e; inside cluster only we have to give access
Whenever we create service then we get one-extra service because k8's will have one default ClusterIp service along with our service.


apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: swiggy
  name: swiggy-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
      - name: cont1
        image: rahamshaik/moviespaytm:latest
        ports:
          - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: sv1
spec:
  type: ClusterIP
  selector:
    app: swiggy
  ports:
    - port: 80

DRAWBACK:
We cannot use app outside.

1.Depends of cluster requirment and type of the node we will give alltraffic.Generally we dont give all traffic.
2.Depends upon type of Server Security Group will change
3.If it is application server then we should give port number 8080
4.If it is DataBase server like PostGre then we should give portnumber 5432

2. NODEPORT: It will expose the application in 'particular port number only'.
Range: 30000 - 32767 (in sg we need to give all traffic)
ChatGpt will have 5k workernodes

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: swiggy
  name: swiggy-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
      - name: cont1
        image: rahamshaik/trainservice:latest
        ports:
          - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: abc
spec:
  type: NodePort
  selector:
    app: swiggy
  ports:
    - port: 80
      targetPort: 80
      nodePort: 31111


NOTE: UPDATE THE SG (REMOVE OLD TRAFFIC AND GIVE ALL TRAFFIC & SSH)
DRAWBACK:
PORT RESTRICTION.

3. LOADBALACER: It will expose our application and distribute load bw pods.

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: swiggy
  name: swiggy-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
      - name: cont1
        image: rahamshaik/trainservice:latest
        ports:
          - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: abc
spec:
  type: LoadBalancer
  selector:
    app: swiggy
  ports:
    - port: 80
      targetPort: 80

EXTERNAL IP in LOAD BALANCER means LD DNS
LOAD BALANCER will doesnot suport port numbers which is distributes the loads to servers
EX: If we have 2 Nodes then Users accessing the server then LoadBalancer distribute the Load 
    1.One User accessing Node1
    2.Other User accessing Node2

======================================================================
  
CONFIGMAPS & SECRETS: It is a way of passing variables to k8s pods.
  
ENV VARS: used to define a vlaue.
ENV VARIABLES we can pass on CONTAINER LAVEL, POD LEVEL, DEPLOYMENT LEVEL through 1. MANIFEST FILE  throug 2.CONFIGMAPS  throug 3. SECRETS
LEVEL:
CONTAINER LEVEL
POD LEVEL
DEPLOYMENT LEVEL

in 3 METHODS using
METHODS TO DEFINE:
1. MANIFEST FILE
2. CONFIGMAPS
3. SECRETS

CONFIGMAP:
If we want to pass variables for pods&container we use configmap.
Used to store data in key-value, pass the data through files or pass the data through CLI to the pods, container etc---
in CONFIGMAP data is not going to encrypted, if we want encrypt we need to use secrets.
limit to pass data from ConfigMap is 1 MB only, to store more than 1 MB mount the volume seperately.We cannot pass morethan 1MB of data inside the ConfigMap.


1.Manifest File
key-value:

cat configmap.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: swiggycm
data:
  tomcat_url: "https://192.16.100.10:8080"
  db_url: "https://192.16.100.10:5432"

cat pod.yml
apiVersion: v1
kind: Pod
metadata:
  name: swiggy
spec:
  containers:
    - name: swiggy-cont1
      image: nginx
      envFrom:
        - configMapRef:
            name: swiggycm

kubectl apply -f configmap.yml
kubectl apply -f pod.yml
kubectl describe cm cm1
kubectl describe pod pod1


2. CLI:

kubectl create deploy swiggydb --image=mariadb
kubectl get pods
kubectl create deploy swiggydb --image=mariadb
kubectl logs swiggydb-5d49dc56-cbbqk
kubectl set env deploy swiggydb MYSQL_ROOT_PASSWORD=Raham123 
kubectl get pods

3. Normal FILE

vim varsfile
MYSQL_ROOT_PASSWORD=Raham123
MYSQL_USER=admin

kubectl create cm dbvars --from-env-file=varsfile #This confimap attach to pod
kubectl describe cm dbvars
kubectl get deploy 
kubectl delete deploy swiggydb
kubectl create deploy swiggydb --image=mariadb   #pod
kubectl get pods
kubectl get cm
kubectl set env deploy swiggydb --from=configmap/dbvars
kubectl get pods
kubectl edit deploy swiggydb

SECRETS:

To store sensitive data in an unencrypted format like passwords, ssh-keys etc ---
it uses encryption technique is base64 encoded format
It is Designed to 'prevent'  'exposure' or 'unauthorized access' to sensitive information within the cluster.
Both secrets and Config maps are used for outside of deployment only
config maps cannot encode but secrets will encode the data
password=raham (now we can encode and ecode the value)


K8s supports different types of secrets:
Generic: Generic secrets allow you to store arbitrary key-value pairs.
TLS: To store TLS certificates for securing communication between services.
Docker-registry: Docker-registry secrets are used for storing credentials required to authenticate with private Docker registries.
SSH: To store SSH private keys, used for secure access to external resources.


kubectl get secret
kubectl create secret generic password --from-literal=ROOT_PASSWORD=raham123
kubectl get secrets
kubectl get secrets password -o yaml
echo "cmFoYW0xMjM=" | base64 --decode
echo "cmFoYW0xMjM=" | base64 -d

Q.How to deploy a perticular pod in perticular node?
A)using taint and tolaretion concept
  
============================================================


HISTORY:

 1  vim kops.sh
    2  vim .bashrc
    3  source .bashrc
    4  sh kops.sh
    5  vim .aws/credentials
    6  sh kops.sh
    7  kubectl get no
    8  kops get cluster
    9  cat kops.sh
   10  export KOPS_STATE_STORE=s3://viratkohli77.k8s.local
   11  cat kops.sh
   12  kops get cluster
   13  kubectl get no
   14  vim abc.yml
   15  kubectl apply -f abc.yml
   16  kubectl get deploy
   17  kubectl get svc
   18  kubectl delete -f abc.yml
   19  vim abc.yml
   20  kubectl apply -f abc.yml
   21  kubectl get svc,deploy
   22  kubectl get po -o wide
   23  vim abc.yml
   24  kubectl apply -f abc.yml
   25  kubectl get svc,deploy
   26  kubectl delete -f abc.yml
   27  vim abc.yml
   28  kubectl apply -f abc.yml
   29  kubectl get svc,deploy
   30  kubectl delete -f abc.yml
   31  rm -rf *
   32  vim configmap.yml
   33  vim pod.yml
   34  kubectl apply -f configmap.yml
   35  kubectl apply -f pod.yml
   36  kubectl get po
   37  kubectl describe pod swiggy
   38  kubectl api-resources
   39  kubectl api-resources | grep -i cm
   40  kubectl get cm
   41  kubectl describe cm swiggycm
   42  kubectl create deploy swiggydb --image=mariadb
   43  kubectl get deploy
   44  kubectl get po
   45  kubectl logs swiggydb-6b66f8997f-vbhmg
   46  kubectl set env deploy swiggydb MYSQL_ROOT_PASSWORD=Raham123
   47  kubectl get po
   48  vim varsfile
   49  kubectl create cm dbvars --from-env-file=varsfile   #This confimap attach to pod
   50  kubectl get cm
   51  kubectl create deploy swiggydb --image=mariadb
   52  kubectl delete pod swiggydb
   53  kubectl delete deploy swiggydb
   54  kubectl create deploy swiggydb --image=mariadb   #POD
   55  kubectl get po
   56  kubectl set env deploy swiggydb --from=configmap/dbvars
   57  kubectl get po
   58  kubectl get secret
   59  kubectl create secret generic password --from-literal=ROOT_PASSWORD=raham123
   60  kubectl get secrets
   61  kubectl get secrets password -o yaml
   62  echo "cmFoYW0xMjM=" | base64 --decode
   63  history

curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
chmod +x kops-linux-amd64 kubectl
mv kubectl /usr/local/bin/kubectl
mv kops-linux-amd64 /usr/local/bin/kops
aws s3api create-bucket --bucket chotape1234 --region eu-west-1 --create-bucket-configuration LocationConstraint=eu-west-1
aws s3api put-bucket-versioning --bucket chotape1234 --region eu-west-1 --versioning-configuration Status=Enabled
export KOPS_STATE_STORE=s3://chotape1233

